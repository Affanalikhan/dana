"""
Run Enhanced Training Data Generation
Execute the comprehensive training data generation with all requirements
"""

import os
import sys
from pathlib import Path
from enhanced_comprehensive_generator import EnhancedComprehensiveGenerator

def main():
    """Run the enhanced training data generation"""
    
    print("ğŸš€ ENHANCED NEURAL TRAINING DATA GENERATION")
    print("="*60)
    
    # Check API key
    api_key = os.getenv('GROQ_API_KEY')
    if not api_key:
        print("âŒ Error: GROQ_API_KEY not found in environment variables")
        print("\nPlease add your Groq API key to the .env file:")
        print("GROQ_API_KEY=your_api_key_here")
        return False
    
    print("âœ… API key found")
    
    # Initialize generator
    try:
        generator = EnhancedComprehensiveGenerator(api_key)
        print("âœ… Generator initialized")
    except Exception as e:
        print(f"âŒ Error initializing generator: {e}")
        return False
    
    # Generate dataset
    try:
        print("\nğŸ¯ Starting comprehensive dataset generation...")
        print("This will generate training data covering:")
        print("   â€¢ 8 business domains (SaaS, Retail, Finance, Healthcare, etc.)")
        print("   â€¢ 66+ total conversations")
        print("   â€¢ 1,300+ strategic business questions")
        print("   â€¢ Progressive questioning with 5-7 questions per batch")
        print("   â€¢ At least 6 of 8 dimension categories covered")
        print("   â€¢ Contextual multiple-choice options")
        print("   â€¢ Adaptive follow-up questions")
        
        confirm = input("\nProceed with generation? (y/N): ").lower().strip()
        if confirm != 'y':
            print("Generation cancelled.")
            return False
        
        stats = generator.generate_complete_dataset()
        
        # Validate results
        if stats['compliance_score'] >= 90:
            print(f"\nğŸ‰ SUCCESS! Dataset generated with {stats['compliance_score']:.1f}% compliance")
            print("\nğŸ“Š Final Statistics:")
            print(f"   Total Conversations: {stats['generation_metadata']['total_conversations']}")
            print(f"   Total Questions: {stats['generation_metadata']['total_questions']}")
            print(f"   Domains Covered: {stats['domain_coverage']['domains_generated']}/8")
            print(f"   Dimensions Covered: {stats['dimension_coverage']['dimensions_covered']}/8")
            print(f"   Average Questions per Conversation: {stats['quality_metrics']['avg_questions_per_conversation']:.1f}")
            
            print(f"\nâœ… Requirements Met:")
            for req, status in stats['requirements_compliance'].items():
                print(f"   {req.replace('_', ' ').title()}: {'âœ…' if status else 'âŒ'}")
            
            print(f"\nğŸ“ Files generated in: ./enhanced_training_data/")
            print("Ready for neural model training!")
            return True
        else:
            print(f"\nâš ï¸ Warning: Dataset compliance is {stats['compliance_score']:.1f}%")
            print("Some requirements may not be fully met.")
            return False
            
    except Exception as e:
        print(f"âŒ Error during generation: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)